name: Run Databricks Notebooks

on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - 'notebooks/**'
      - '.github/workflows/notebooks.yaml'

jobs:
  run-databricks-command:
    runs-on: ubuntu-latest
    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Install Databricks CLI
        run: |
          pip install databricks-cli
          databricks jobs configure --version=2.1

      - name: Run Databricks command
        run: |
          for file in jobs/*.json; do
            echo "Processing $file ..."
            JOB_NAME=$(jq -r .name "$file")
            if [ -z "$JOB_NAME" ] || [ "$JOB_NAME" == "null" ]; then
              echo "  Skipping $file because it has no 'name' field"
              continue
            fi

            JOB_ID=$(databricks jobs list --output JSON | jq -r --arg name "$JOB_NAME" '.jobs[] | select(.settings.name == $name) | .job_id')

            if [ -z "$JOB_ID" ]; then
              echo "  Creating new job: $JOB_NAME"
              databricks jobs create --json "$(cat "$file")"
            else
              echo "  Updating existing job: $JOB_NAME with ID $JOB_ID"
              databricks jobs reset --job-id "$JOB_ID" --json "$(cat "$file")"
            fi
          done
